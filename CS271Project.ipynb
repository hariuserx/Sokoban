{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637699308.752365\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open(\"./Input/sokoban_prof.txt\")\n",
    "\n",
    "lines = []\n",
    "for eachline in myfile:\n",
    "    lines.append(eachline)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 19\n"
     ]
    }
   ],
   "source": [
    "# Input Line0\n",
    "sizeH = int(lines[0].split()[0])\n",
    "sizeV = int(lines[0].split()[1])\n",
    "\n",
    "print(sizeH, sizeV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into a set\n",
    "# Arrays are in (y,x), with top row as 1, and leftmost column as 1\n",
    "def createCoordinatesSet(inputArray):\n",
    "    coordinates = set([])\n",
    "    for i,j in zip(inputArray[0::2], inputArray[1::2]):\n",
    "        coordinates.add((int(i), int(j)))\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "{(6, 18), (6, 15), (4, 3), (4, 9), (9, 2), (9, 5), (5, 10), (9, 8), (9, 14), (11, 5), (1, 6), (9, 11), (2, 5), (10, 12), (1, 9), (10, 18), (11, 8), (10, 15), (11, 11), (6, 2), (7, 1), (7, 7), (6, 5), (7, 10), (6, 8), (6, 14), (7, 13), (7, 19), (6, 17), (4, 5), (3, 9), (5, 3), (9, 1), (9, 7), (9, 4), (11, 7), (10, 5), (10, 11), (9, 13), (9, 19), (11, 10), (1, 5), (10, 14), (6, 1), (1, 8), (10, 17), (6, 7), (7, 12), (6, 10), (6, 16), (6, 19), (3, 5), (4, 4), (4, 10), (9, 3), (8, 1), (9, 9), (11, 9), (10, 13), (7, 11), (11, 6), (2, 9), (1, 7), (8, 19), (10, 16), (10, 19), (7, 5), (6, 3), (7, 8), (7, 14)}\n"
     ]
    }
   ],
   "source": [
    "# Input Line1\n",
    "line1Array = lines[1].split()\n",
    "nWallSquares = int(line1Array[0])\n",
    "wallCoordinates = createCoordinatesSet(line1Array[1:])\n",
    "\n",
    "print(nWallSquares)\n",
    "print(wallCoordinates)\n",
    "\n",
    "if (len(wallCoordinates)!=nWallSquares):\n",
    "    print(\"Wall square does not match, check input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{(5, 8), (8, 3), (5, 6), (4, 8), (3, 6), (8, 6)}\n"
     ]
    }
   ],
   "source": [
    "# Input Line2\n",
    "line2Array = lines[2].split()\n",
    "nBoxes = int(line2Array[0])\n",
    "boxCoordinates = createCoordinatesSet(line2Array[1:])\n",
    "\n",
    "print(nBoxes)\n",
    "print(boxCoordinates)\n",
    "\n",
    "if (len(boxCoordinates)!=nBoxes):\n",
    "    print(\"Boxes does not match, check input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{(7, 17), (8, 17), (9, 18), (8, 18), (9, 17), (7, 18)}\n"
     ]
    }
   ],
   "source": [
    "# Input Line3\n",
    "line3Array = lines[3].split()\n",
    "nStorageLocations = int(line3Array[0])\n",
    "storageCoordinates = createCoordinatesSet(line3Array[1:])\n",
    "\n",
    "print(nStorageLocations)\n",
    "print(storageCoordinates)\n",
    "\n",
    "if (len(storageCoordinates)!=nStorageLocations):\n",
    "    print(\"Wall square does not match, check input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 12)\n"
     ]
    }
   ],
   "source": [
    "# Input Line4\n",
    "line4Array = lines[4].split()\n",
    "initialLocation = (int(line4Array[0]), int(line4Array[1]))\n",
    "\n",
    "print(initialLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "actions = ['U', 'D', 'L', 'R']\n",
    "discount = 1.0\n",
    "learningRate = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SokobanState:\n",
    "    def __init__(self, wallCoordinates, boxCoordinates, storageCoordinates, location):\n",
    "        self.WallCoordinates = frozenset(wallCoordinates.copy())\n",
    "        self.BoxCoordinates = frozenset(boxCoordinates.copy())\n",
    "        self.StorageCoordinates = frozenset(storageCoordinates.copy())\n",
    "        self.Location = location\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash((self.BoxCoordinates, self.Location))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.BoxCoordinates, self.Location) == (other.BoxCoordinates, other.Location)\n",
    "    \n",
    "    def minStepsBetweenCoordinates(self, coordinates1, coordinates2):\n",
    "        return abs(coordinates1[0]-coordinates2[0]) + abs(coordinates1[1]-coordinates2[1])\n",
    "    \n",
    "    def totalBoxToClosestStorageSteps(self):\n",
    "        result = 0\n",
    "        for box in self.BoxCoordinates.difference(self.StorageCoordinates):\n",
    "            minFound = float(\"inf\")\n",
    "            for storage in self.StorageCoordinates.difference(self.BoxCoordinates):\n",
    "                steps = self.minStepsBetweenCoordinates(box, storage)\n",
    "                if steps < minFound:\n",
    "                    minFound = steps\n",
    "            result += minFound\n",
    "        return result\n",
    "    \n",
    "    def agentToClosestBoxSteps(self):\n",
    "        minFound = float(\"inf\")\n",
    "        for box in self.BoxCoordinates.difference(self.StorageCoordinates):\n",
    "            steps = self.minStepsBetweenCoordinates(self.Location, box)\n",
    "            if steps < minFound:\n",
    "                minFound = steps\n",
    "        return minFound\n",
    "    \n",
    "    def remainingBoxes(self):\n",
    "        count = 0\n",
    "        for box in self.BoxCoordinates.difference(self.StorageCoordinates):\n",
    "            count += 1\n",
    "        return count\n",
    "    \n",
    "    def isTerminal(self):\n",
    "        return all(map(lambda BoxCoor: BoxCoor in self.StorageCoordinates, self.BoxCoordinates))\n",
    "    \n",
    "    def boxStuckAtCorner(self, box):\n",
    "        if box in self.StorageCoordinates:\n",
    "            return False\n",
    "        coordinateDifference = [(-1,-1), (-1,+1), (+1, -1), (+1,+1)]\n",
    "        for difference in coordinateDifference:\n",
    "            if (box[0]+difference[0], box[1]) in self.WallCoordinates and (box[0], box[1]+difference[1]) in self.WallCoordinates:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def noSolution(self):\n",
    "        return any(map(lambda BoxCoor: self.boxStuckAtCorner(BoxCoor), self.BoxCoordinates))\n",
    "    \n",
    "    def getTargetLocations(self, action):\n",
    "        currentLocation = self.Location\n",
    "        targetLocation = currentLocation\n",
    "        targetNextLocation = (currentLocation[0]+1, currentLocation[1])\n",
    "        if action == 'U':\n",
    "            targetLocation = (currentLocation[0]-1, currentLocation[1])\n",
    "            targetNextLocation = (currentLocation[0]-2, currentLocation[1])\n",
    "        elif action == 'D':\n",
    "            targetLocation = (currentLocation[0]+1, currentLocation[1])\n",
    "            targetNextLocation = (currentLocation[0]+2, currentLocation[1])\n",
    "        elif action == 'L':\n",
    "            targetLocation = (currentLocation[0], currentLocation[1]-1)\n",
    "            targetNextLocation = (currentLocation[0], currentLocation[1]-2)\n",
    "        elif action == 'R':\n",
    "            targetLocation = (currentLocation[0], currentLocation[1]+1)\n",
    "            targetNextLocation = (currentLocation[0], currentLocation[1]+2)\n",
    "        return (targetLocation, targetNextLocation)\n",
    "    \n",
    "    def isInvalidAction(self, action):\n",
    "        targetLocation, targetNextLocation = self.getTargetLocations(action)\n",
    "        return (targetLocation in self.WallCoordinates) or (targetLocation in self.BoxCoordinates and targetNextLocation in self.BoxCoordinates) or (targetLocation in self.BoxCoordinates and targetNextLocation in self.WallCoordinates)\n",
    "    \n",
    "    # Avoid agent stuck at local maximum by staying at the same location, only allow movable actions\n",
    "    def getPossibleActions(self):\n",
    "        return [action for action in actions if not self.isInvalidAction(action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sokoban:\n",
    "    qFunction = {}\n",
    "    \n",
    "    def __init__(self, sizeH, sizeV, wallCoordinates, boxCoordinates, storageCoordinates, location):\n",
    "        self.SizeH = sizeH\n",
    "        self.SizeV = sizeV\n",
    "        self.currentState = SokobanState(wallCoordinates.copy(), boxCoordinates.copy(), storageCoordinates.copy(), location)\n",
    "\n",
    "    def resetQFunction(self):\n",
    "        self.__class__.qFunction.clear()\n",
    "        \n",
    "    def getQValue(self, state, action):\n",
    "        if state.isTerminal():\n",
    "            return 10000000\n",
    "        if state.noSolution():\n",
    "            return -10000000\n",
    "        return self.__class__.qFunction.get((state, action), 0)\n",
    "    \n",
    "    def setQValue(self, state, action, newValue):\n",
    "        self.__class__.qFunction[(state, action)] = newValue\n",
    "    \n",
    "    def getCurrentStateActions(self):\n",
    "        return self.currentState.getPossibleActions()\n",
    "    \n",
    "    def getMaxQValue(self, state, possibleActions):\n",
    "        return max(map(lambda action: self.getQValue(state, action), possibleActions))\n",
    "    \n",
    "    def getBestAction(self, state):\n",
    "        possibleActions = state.getPossibleActions()\n",
    "        maxQValue = self.getMaxQValue(state, possibleActions)\n",
    "        for action in possibleActions:\n",
    "            if self.getQValue(state, action) == maxQValue:\n",
    "                return action\n",
    "    \n",
    "    # create S'\n",
    "    def createStateForAction(self, state, action):\n",
    "        targetLocation, targetNextLocation = state.getTargetLocations(action)\n",
    "        newLocation = targetLocation\n",
    "        # map frozenset back to a mutable set\n",
    "        newBoxCoordinates = set(state.BoxCoordinates.copy())\n",
    "        if targetLocation in newBoxCoordinates:\n",
    "            newBoxCoordinates.remove(targetLocation)\n",
    "            newBoxCoordinates.add(targetNextLocation)\n",
    "        return SokobanState(state.WallCoordinates, newBoxCoordinates, state.StorageCoordinates, newLocation)\n",
    "        \n",
    "    # Take action A, observe R and S'\n",
    "    # Update Q value\n",
    "    # Update S to S'\n",
    "    def takeAction(self, action):\n",
    "        newState = self.createStateForAction(self.currentState, action)\n",
    "        \n",
    "        # Reward R\n",
    "        R = -1\n",
    "        # Reward for moving box closer\n",
    "        stepDifference = newState.totalBoxToClosestStorageSteps() - self.currentState.totalBoxToClosestStorageSteps()\n",
    "        if stepDifference < 0:\n",
    "            R += 3\n",
    "        elif stepDifference == 0:\n",
    "            R += -3\n",
    "        \n",
    "        # Reward for agent getting closer to a box\n",
    "        distanceToClosestBoxDifference = newState.agentToClosestBoxSteps() - self.currentState.agentToClosestBoxSteps()\n",
    "        if distanceToClosestBoxDifference < 0:\n",
    "            R += 1\n",
    "        elif distanceToClosestBoxDifference > 0:\n",
    "            R += -1\n",
    "        \n",
    "        # Reward for moving box to Storage\n",
    "        remainingBoxesDifference = newState.remainingBoxes() - self.currentState.remainingBoxes()\n",
    "        if remainingBoxesDifference < 0:\n",
    "            R += 15\n",
    "        elif remainingBoxesDifference > 0:\n",
    "            R += -10\n",
    "        \n",
    "        currentQValue = self.getQValue(self.currentState, action)\n",
    "        newQValue = currentQValue + learningRate*(R+discount*self.getMaxQValue(newState, newState.getPossibleActions())-currentQValue)\n",
    "        #newQValue = currentQValue + learningRate*(R+discount*self.getQValue(newState, action)-currentQValue)\n",
    "        self.setQValue(self.currentState, action, newQValue)\n",
    "        self.currentState = newState\n",
    "    \n",
    "    def getPath(self, maxSteps, startState):\n",
    "        path = ''\n",
    "        prevState = startState\n",
    "        tmpState = startState\n",
    "        for i in range(maxSteps):\n",
    "            if tmpState.isTerminal():\n",
    "                print(\"Reached terminal state\")\n",
    "                break\n",
    "            \n",
    "            # May need this part to avoid stuck at local maximum\n",
    "#             bestNextState = None\n",
    "#             bestAction = None\n",
    "#             bestQ = -float(\"inf\")\n",
    "#             for action in tmpState.getPossibleActions():\n",
    "#                 checkState = self.createStateForAction(tmpState, action)\n",
    "#                 qValue = self.getQValue(tmpState, action)\n",
    "#                 if qValue >= bestQ and checkState != prevState:\n",
    "#                     bestState = checkState\n",
    "#                     bestAction = action\n",
    "#                     bestQ = qValue\n",
    "#             #print(tmpState.getPossibleActions())\n",
    "#             #print(list(map(lambda action: self.getQValue(tmpState, action), tmpState.getPossibleActions())))\n",
    "#             #print(bestAction)\n",
    "#             #print(self.getBestAction(tmpState))\n",
    "#             #print(tmpState.Location)\n",
    "#             path += bestAction\n",
    "#             prevState = tmpState\n",
    "#             tmpState = bestState\n",
    "                    \n",
    "            bestAction = self.getBestAction(tmpState)\n",
    "            newState = self.createStateForAction(tmpState, bestAction)\n",
    "            path += bestAction\n",
    "            prevState = tmpState\n",
    "            tmpState = newState\n",
    "           \n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sokoban = Sokoban(sizeH, sizeV, wallCoordinates, boxCoordinates, storageCoordinates, initialLocation)\n",
    "sokoban.resetQFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "def createRandomStartLocation():\n",
    "    randomLocation = (1,1)\n",
    "    while randomLocation in wallCoordinates or randomLocation in boxCoordinates or randomLocation in storageCoordinates:\n",
    "        randomLocation = (random.randint(1, sizeH), random.randint(1, sizeV))\n",
    "    return randomLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndRunEpisode(startLocation, maxSteps, epsilon):\n",
    "    # Return True if this episode reached terminal state\n",
    "    sokoban = Sokoban(sizeH, sizeV, wallCoordinates, boxCoordinates, storageCoordinates, startLocation)\n",
    "    \n",
    "    path = \"\"\n",
    "    for j in range(maxSteps):\n",
    "        if random.random() < epsilon:\n",
    "            action = random.choice(sokoban.currentState.getPossibleActions())\n",
    "        else:\n",
    "            action = sokoban.getBestAction(sokoban.currentState)\n",
    "        sokoban.takeAction(action)\n",
    "        path += action\n",
    "        if sokoban.currentState.isTerminal():\n",
    "            print(\"Stpes used to reach terminal: \", j+1)\n",
    "            print(\"@@@@@: \", path)\n",
    "            return True\n",
    "        if sokoban.currentState.noSolution():\n",
    "            #print(\"%%%%%%: \", path)\n",
    "            return False\n",
    "    #print(\"#####: \", path)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total episodes:  501600\n",
      "Total Completed Episodes:  0\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  0.07014989852905273\n",
      "Total Completed Episodes:  1000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  15.211434841156006\n",
      "Total Completed Episodes:  2000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  31.231566905975342\n",
      "Total Completed Episodes:  3000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  50.13042402267456\n",
      "Total Completed Episodes:  4000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  78.31968879699707\n",
      "Total Completed Episodes:  5000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  98.41941785812378\n",
      "Total Completed Episodes:  6000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  118.74219489097595\n",
      "Total Completed Episodes:  7000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  148.27334690093994\n",
      "Total Completed Episodes:  8000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  174.3344168663025\n",
      "Total Completed Episodes:  9000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  198.51857900619507\n",
      "Total Completed Episodes:  10000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  222.37441778182983\n",
      "Total Completed Episodes:  11000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  240.76968789100647\n",
      "Total Completed Episodes:  12000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  266.0558168888092\n",
      "Total Completed Episodes:  13000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  291.4218728542328\n",
      "Total Completed Episodes:  14000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  323.3884189128876\n",
      "Total Completed Episodes:  15000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  340.823068857193\n",
      "Total Completed Episodes:  16000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  360.4828658103943\n",
      "Total Completed Episodes:  17000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  385.86443996429443\n",
      "Total Completed Episodes:  18000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  411.0288188457489\n",
      "Total Completed Episodes:  19000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  436.6498589515686\n",
      "Total Completed Episodes:  20000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  461.97760367393494\n",
      "Total Completed Episodes:  21000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  476.577027797699\n",
      "Total Completed Episodes:  22000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  498.38150691986084\n",
      "Total Completed Episodes:  23000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  519.4232618808746\n",
      "Total Completed Episodes:  24000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  535.7939620018005\n",
      "Total Completed Episodes:  25000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  552.6763908863068\n",
      "Total Completed Episodes:  26000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  573.4109818935394\n",
      "Total Completed Episodes:  27000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  595.6548628807068\n",
      "Total Completed Episodes:  28000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  614.4570438861847\n",
      "Total Completed Episodes:  29000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  643.9597578048706\n",
      "Total Completed Episodes:  30000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  662.7067768573761\n",
      "Total Completed Episodes:  31000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  680.4422178268433\n",
      "Total Completed Episodes:  32000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  702.2835409641266\n",
      "Total Completed Episodes:  33000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  725.5053198337555\n",
      "Total Completed Episodes:  34000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  751.2128100395203\n",
      "Total Completed Episodes:  35000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  782.2816188335419\n",
      "Total Completed Episodes:  36000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  803.8710868358612\n",
      "Total Completed Episodes:  37000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  826.1294567584991\n",
      "Total Completed Episodes:  38000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  851.9763457775116\n",
      "Total Completed Episodes:  39000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  876.1402039527893\n",
      "Total Completed Episodes:  40000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  897.2713737487793\n",
      "Total Completed Episodes:  41000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  921.7989299297333\n",
      "Total Completed Episodes:  42000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  950.4566309452057\n",
      "Total Completed Episodes:  43000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  971.040235042572\n",
      "Total Completed Episodes:  44000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  993.0084726810455\n",
      "Total Completed Episodes:  45000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1015.0181968212128\n",
      "Total Completed Episodes:  46000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1038.4975349903107\n",
      "Total Completed Episodes:  47000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1060.3859567642212\n",
      "Total Completed Episodes:  48000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1083.510400056839\n",
      "Total Completed Episodes:  49000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1103.9888997077942\n",
      "Total Completed Episodes:  50000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1128.0167899131775\n",
      "Total Completed Episodes:  51000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1148.6077299118042\n",
      "Total Completed Episodes:  52000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1171.2860379219055\n",
      "Total Completed Episodes:  53000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1196.2705399990082\n",
      "Total Completed Episodes:  54000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1228.8345630168915\n",
      "Total Completed Episodes:  55000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1261.59277009964\n",
      "Total Completed Episodes:  56000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1284.6615397930145\n",
      "Total Completed Episodes:  57000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1320.8909668922424\n",
      "Total Completed Episodes:  58000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1345.433117866516\n",
      "Total Completed Episodes:  59000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1373.5940659046173\n",
      "Total Completed Episodes:  60000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1393.9259378910065\n",
      "Total Completed Episodes:  61000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1414.1729958057404\n",
      "Total Completed Episodes:  62000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1434.907243013382\n",
      "Total Completed Episodes:  63000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1456.7542078495026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Completed Episodes:  64000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1478.3138718605042\n",
      "Total Completed Episodes:  65000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1499.001569032669\n",
      "Total Completed Episodes:  66000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1523.6365218162537\n",
      "Total Completed Episodes:  67000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1547.2542657852173\n",
      "Total Completed Episodes:  68000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1567.8182399272919\n",
      "Total Completed Episodes:  69000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1585.7316389083862\n",
      "Total Completed Episodes:  70000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1604.7623269557953\n",
      "Total Completed Episodes:  71000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1625.7247428894043\n",
      "Total Completed Episodes:  72000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1650.2610409259796\n",
      "Total Completed Episodes:  73000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1675.6572086811066\n",
      "Total Completed Episodes:  74000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1694.3519968986511\n",
      "Total Completed Episodes:  75000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1712.7334849834442\n",
      "Total Completed Episodes:  76000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1732.722857952118\n",
      "Total Completed Episodes:  77000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1751.6037418842316\n",
      "Total Completed Episodes:  78000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1771.0787858963013\n",
      "Total Completed Episodes:  79000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1793.6951339244843\n",
      "Total Completed Episodes:  80000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1813.2912368774414\n",
      "Total Completed Episodes:  81000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1835.7614228725433\n",
      "Total Completed Episodes:  82000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1860.9525129795074\n",
      "Total Completed Episodes:  83000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1881.7538979053497\n",
      "Total Completed Episodes:  84000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1900.9117288589478\n",
      "Total Completed Episodes:  85000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1926.1717088222504\n",
      "Total Completed Episodes:  86000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1946.2686989307404\n",
      "Total Completed Episodes:  87000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1966.3120539188385\n",
      "Total Completed Episodes:  88000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  1987.2203760147095\n",
      "Total Completed Episodes:  89000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2005.5344247817993\n",
      "Total Completed Episodes:  90000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2024.7209258079529\n",
      "Total Completed Episodes:  91000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2042.8015370368958\n",
      "Total Completed Episodes:  92000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2061.567407846451\n",
      "Total Completed Episodes:  93000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2084.742197036743\n",
      "Total Completed Episodes:  94000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2105.4370498657227\n",
      "Total Completed Episodes:  95000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2125.586707830429\n",
      "Total Completed Episodes:  96000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2145.524834871292\n",
      "Total Completed Episodes:  97000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2167.911376953125\n",
      "Total Completed Episodes:  98000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2188.2998337745667\n",
      "Total Completed Episodes:  99000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2210.1091027259827\n",
      "Total Completed Episodes:  100000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2232.167363882065\n",
      "Total Completed Episodes:  101000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  2259.7184188365936\n",
      "Total Completed Episodes:  102000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  3197.588574886322\n",
      "Total Completed Episodes:  103000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  3219.579163789749\n",
      "Total Completed Episodes:  104000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  3238.9422850608826\n",
      "Total Completed Episodes:  105000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  3256.226761817932\n",
      "Total Completed Episodes:  106000\n",
      "Episodes reached terminal state in the last 1000 Episodes:  0\n",
      "Time elapsed:  3272.8520550727844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lk/vvhpbsn93kn3bypr_qxdlpx00000gn/T/ipykernel_89548/931739464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Q-learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mepisodeReachedTerminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateAndRunEpisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialLocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxSteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepisodeReachedTerminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mterminalCount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/vvhpbsn93kn3bypr_qxdlpx00000gn/T/ipykernel_89548/966350921.py\u001b[0m in \u001b[0;36mcreateAndRunEpisode\u001b[0;34m(startLocation, maxSteps, epsilon)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msokoban\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetBestAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msokoban\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msokoban\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakeAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msokoban\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misTerminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/vvhpbsn93kn3bypr_qxdlpx00000gn/T/ipykernel_89548/4211343378.py\u001b[0m in \u001b[0;36mtakeAction\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcurrentQValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mnewQValue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrentQValue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdiscount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMaxQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPossibleActions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcurrentQValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;31m#newQValue = currentQValue + learningRate*(R+discount*self.getQValue(newState, action)-currentQValue)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewQValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/vvhpbsn93kn3bypr_qxdlpx00000gn/T/ipykernel_89548/4211343378.py\u001b[0m in \u001b[0;36mgetMaxQValue\u001b[0;34m(self, state, possibleActions)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetMaxQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibleActions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibleActions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetBestAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/vvhpbsn93kn3bypr_qxdlpx00000gn/T/ipykernel_89548/4211343378.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(action)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetMaxQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibleActions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibleActions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetBestAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/vvhpbsn93kn3bypr_qxdlpx00000gn/T/ipykernel_89548/4211343378.py\u001b[0m in \u001b[0;36mgetQValue\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoSolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetQValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/lk/vvhpbsn93kn3bypr_qxdlpx00000gn/T/ipykernel_89548/1921239259.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoxCoordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoxCoordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoxCoordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = sizeH*sizeV*nBoxes*4*100\n",
    "maxSteps = sizeH*sizeV*nBoxes*2\n",
    "terminalCount = 0\n",
    "epsilon = 0.2\n",
    "print('Total episodes: ', episodes)\n",
    "# Q-learning\n",
    "for i in range(episodes):\n",
    "    episodeReachedTerminal = createAndRunEpisode(initialLocation, maxSteps, epsilon)\n",
    "    if episodeReachedTerminal:\n",
    "        terminalCount += 1\n",
    "        break\n",
    "    if i%1000 == 0:\n",
    "        print(\"Total Completed Episodes: \", i)\n",
    "        print(\"Episodes reached terminal state in the last 1000 Episodes: \", terminalCount)\n",
    "        tmpSokoban = Sokoban(sizeH, sizeV, wallCoordinates, boxCoordinates, storageCoordinates, initialLocation)\n",
    "        #currentBestPath = tmpSokoban.getPath(maxSteps, tmpSokoban.currentState)\n",
    "        #print(len(currentBestPath), \" \", currentBestPath)\n",
    "        # if we have a good enough policy, we should have a high chance of reaching the terminal state, so we can terminate\n",
    "        if terminalCount > 500:\n",
    "            print(\"Early terminate\")\n",
    "            break\n",
    "        timeElapsed = time.time() - start\n",
    "        print('Time elapsed: ', timeElapsed)\n",
    "        if timeElapsed > 3600:\n",
    "            print('Timeout')\n",
    "            break\n",
    "        terminalCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sokoban = Sokoban(sizeH, sizeV, wallCoordinates, boxCoordinates, storageCoordinates, initialLocation)\n",
    "#path = sokoban.getPath(maxSteps, sokoban.currentState)\n",
    "#print(len(path), \" \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print('Execution time: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
